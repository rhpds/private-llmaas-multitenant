image: registry.redhat.io/rhaiis/vllm-cuda-rhel9:3.2.5

models:
  - name: qwen3-14b-fp8
    displayName: Qwen3 14B FP8
    uri: oci://quay.io/jharmison/models:qwen--qwen3-14b-fp8-modelcar
    resources:
      limits:
        cpu: "6"
        memory: 48Gi
        nvidia.com/gpu: "1"
      requests:
        cpu: "4"
        memory: 32Gi
        nvidia.com/gpu: "1"
    extraArgs:
      - --enable-auto-tool-choice
      - --tool-call-parser=hermes
    tolerations:
      - effect: NoSchedule
        key: nvidia.com/gpu
        operator: Equal
        value: l40-gpu
  - name: llama-guard-3-1b
    displayName: Llama Guard 3 1B
    uri: oci://quay.io/rh-aiservices-bu/llama-guard-3-1b-modelcar:2.0.0
    resources:
      limits:
        cpu: "6"
        memory: 24Gi
        nvidia.com/gpu: "1"
      requests:
        cpu: "4"
        memory: 16Gi
        nvidia.com/gpu: "1"
    extraArgs:
      - --max-model-len=6048
      - --dtype=half
      - --enable-chunked-prefill
    tolerations:
      - effect: NoSchedule
        key: nvidia.com/gpu
        operator: Equal
        value: l4-gpu
